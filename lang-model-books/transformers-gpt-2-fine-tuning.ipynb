{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers -q\n!pip install wandb -q","metadata":{"execution":{"iopub.status.busy":"2023-01-25T12:22:53.463584Z","iopub.execute_input":"2023-01-25T12:22:53.464253Z","iopub.status.idle":"2023-01-25T12:23:15.778868Z","shell.execute_reply.started":"2023-01-25T12:22:53.463861Z","shell.execute_reply":"2023-01-25T12:23:15.777567Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"#import wandb\n#wandb.login()\n#wandb.init(project=\"gpt-2-fine-tuning\", entity=\"bilalcelebi23\")","metadata":{"execution":{"iopub.status.busy":"2023-01-25T12:23:15.781506Z","iopub.execute_input":"2023-01-25T12:23:15.782568Z","iopub.status.idle":"2023-01-25T12:23:26.751252Z","shell.execute_reply.started":"2023-01-25T12:23:15.782522Z","shell.execute_reply":"2023-01-25T12:23:26.750319Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbilalcelebi23\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.13.9 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.12.21"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230125_122320-1fhrebmy</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href=\"https://wandb.ai/bilalcelebi23/gpt-2-fine-tuning/runs/1fhrebmy\" target=\"_blank\">fortuitous-fireworks-2</a></strong> to <a href=\"https://wandb.ai/bilalcelebi23/gpt-2-fine-tuning\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"execution_count":2,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/bilalcelebi23/gpt-2-fine-tuning/runs/1fhrebmy?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7fc35da41390>"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\n\ndata_path = '/kaggle/input/business-ideas-generated-with-gpt3/ideas.csv'\ndata = pd.read_csv(data_path)\ndata.columns = ['content']\ndata = data['content'].unique()\nlen(data)","metadata":{"execution":{"iopub.status.busy":"2023-01-25T12:23:26.755900Z","iopub.execute_input":"2023-01-25T12:23:26.758080Z","iopub.status.idle":"2023-01-25T12:23:29.478022Z","shell.execute_reply.started":"2023-01-25T12:23:26.758040Z","shell.execute_reply":"2023-01-25T12:23:29.477018Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"31536"},"metadata":{}}]},{"cell_type":"code","source":"train_size = int(len(data) * 0.8)\ntrain_data = data[:train_size]\ntest_data = data[train_size:]\nlen(train_data), len(test_data)","metadata":{"execution":{"iopub.status.busy":"2023-01-25T12:23:29.484294Z","iopub.execute_input":"2023-01-25T12:23:29.487054Z","iopub.status.idle":"2023-01-25T12:23:29.500152Z","shell.execute_reply.started":"2023-01-25T12:23:29.487013Z","shell.execute_reply":"2023-01-25T12:23:29.499000Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(25228, 6308)"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import DataCollatorForLanguageModeling, DataCollatorWithPadding, GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments, AutoConfig\nfrom datasets import Dataset\n\nmodel = GPT2LMHeadModel.from_pretrained('gpt2')\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2')","metadata":{"execution":{"iopub.status.busy":"2023-01-25T12:23:29.505405Z","iopub.execute_input":"2023-01-25T12:23:29.508457Z","iopub.status.idle":"2023-01-25T12:24:07.658076Z","shell.execute_reply.started":"2023-01-25T12:23:29.508420Z","shell.execute_reply":"2023-01-25T12:24:07.657063Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28f49a27b3864f7596d23dc300aa1e63"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/523M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d598ce3ce89b404789ac27c22a982a91"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f372bd7cfb740aba2647f65a2891dab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f11496b870042209d30a096b142f511"}},"metadata":{}}]},{"cell_type":"code","source":"bos = '<|endoftext|>'\neos = '<|EOS|>'\npad = '<|pad|>'\n\nspecial_tokens_dict = {'eos_token': eos, 'bos_token': bos, 'pad_token': pad}\nnum_add_tokens = tokenizer.add_special_tokens(special_tokens_dict)\n\nconfig = AutoConfig.from_pretrained('gpt2', \n                                    bos_token_id=tokenizer.bos_token_id,\n                                    eos_token_id=tokenizer.eos_token_id,\n                                    pad_token_id=tokenizer.pad_token_id,\n                                    output_hidden_states=False)\n\nmodel = GPT2LMHeadModel.from_pretrained('gpt2', config=config)\nmodel.resize_token_embeddings(len(tokenizer))","metadata":{"execution":{"iopub.status.busy":"2023-01-25T12:24:07.662747Z","iopub.execute_input":"2023-01-25T12:24:07.665683Z","iopub.status.idle":"2023-01-25T12:24:12.881547Z","shell.execute_reply.started":"2023-01-25T12:24:07.665642Z","shell.execute_reply":"2023-01-25T12:24:12.880303Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Embedding(50259, 768)"},"metadata":{}}]},{"cell_type":"code","source":"def prepare_data(data):\n    \n    response = []\n    \n    for pair in data:\n        \n        new_pair = bos + ' ' + str(pair) + ' ' + eos\n        \n        response.append(new_pair)\n        \n    return response","metadata":{"execution":{"iopub.status.busy":"2023-01-25T12:24:12.886551Z","iopub.execute_input":"2023-01-25T12:24:12.889214Z","iopub.status.idle":"2023-01-25T12:24:12.898999Z","shell.execute_reply.started":"2023-01-25T12:24:12.889169Z","shell.execute_reply":"2023-01-25T12:24:12.897645Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_data = prepare_data(train_data)\ntest_data = prepare_data(test_data)\ntest_data[0], train_data[0]","metadata":{"execution":{"iopub.status.busy":"2023-01-25T12:24:12.903834Z","iopub.execute_input":"2023-01-25T12:24:12.906230Z","iopub.status.idle":"2023-01-25T12:24:12.957862Z","shell.execute_reply.started":"2023-01-25T12:24:12.906192Z","shell.execute_reply":"2023-01-25T12:24:12.956925Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"('<|endoftext|> A startup that wants to help people make money off their pets. It’s in early stages, but has already raised $145,000 in seed funding from AngelList. <|EOS|>',\n '<|endoftext|> A 3D printing platform that helps business owners create 3D-printed products <|EOS|>')"},"metadata":{}}]},{"cell_type":"code","source":"train_data = pd.DataFrame(train_data)\ntrain_data.columns = ['content']\ntest_data = pd.DataFrame(test_data)\ntest_data.columns = ['content']","metadata":{"execution":{"iopub.status.busy":"2023-01-25T12:24:12.962491Z","iopub.execute_input":"2023-01-25T12:24:12.964926Z","iopub.status.idle":"2023-01-25T12:24:12.978009Z","shell.execute_reply.started":"2023-01-25T12:24:12.964889Z","shell.execute_reply":"2023-01-25T12:24:12.976961Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_dataset = Dataset.from_pandas(train_data[['content']])\ntest_dataset = Dataset.from_pandas(test_data[['content']])\ntrain_dataset, test_dataset","metadata":{"execution":{"iopub.status.busy":"2023-01-25T12:24:12.985766Z","iopub.execute_input":"2023-01-25T12:24:12.986207Z","iopub.status.idle":"2023-01-25T12:24:13.060531Z","shell.execute_reply.started":"2023-01-25T12:24:12.986172Z","shell.execute_reply":"2023-01-25T12:24:13.059346Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"(Dataset({\n     features: ['content'],\n     num_rows: 25228\n }),\n Dataset({\n     features: ['content'],\n     num_rows: 6308\n }))"},"metadata":{}}]},{"cell_type":"code","source":"def tokenize_func(example):\n    \n    return tokenizer(example['content'], padding = True)\n\ntokenized_train_dataset = train_dataset.map(tokenize_func,\n                                           batched = True,\n                                           num_proc = 5,\n                                           remove_columns = ['content'])\n\ntokenized_test_dataset = test_dataset.map(tokenize_func,\n                                         batched = True,\n                                         num_proc = 5,\n                                         remove_columns = ['content'])","metadata":{"execution":{"iopub.status.busy":"2023-01-25T12:24:13.062327Z","iopub.execute_input":"2023-01-25T12:24:13.062707Z","iopub.status.idle":"2023-01-25T12:24:27.046212Z","shell.execute_reply.started":"2023-01-25T12:24:13.062653Z","shell.execute_reply":"2023-01-25T12:24:27.045110Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"       ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/6 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"baf660e53eea4202b448de385b7aa7ce"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/6 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4859a177558b4efbb72d988ade4120a2"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/6 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9df7393688448209afc2f91b3e5bf11"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/6 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90c1f028d2a5439f96a3b318c9ed4474"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#4:   0%|          | 0/6 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"021253c980e04add83d9a83fe0d32e0e"}},"metadata":{}},{"name":"stdout","text":"       ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c60f8df9fac44868cc8cd08bf10ed6b"}},"metadata":{}},{"name":"stdout","text":"   ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3849bce21ea4e51a886a49ff80749b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d61e2d8d15f54d6d941c2d68c9b5182b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2ad94e2c1e641af86dd259cc1d2f378"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#4:   0%|          | 0/2 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a548eab39802441ba695064193441f77"}},"metadata":{}}]},{"cell_type":"code","source":"model_save_path = '/kaggle/working/fine_tuned_model'\n\ntraining_args = TrainingArguments(\n    output_dir=model_save_path,\n    num_train_epochs=10,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=8,\n    warmup_steps=200,\n    weight_decay=0.01,\n    logging_dir=model_save_path,\n    prediction_loss_only=True,\n    save_steps=10000\n    #report_to = 'wandb'\n)\n\ndata_collator = DataCollatorForLanguageModeling(tokenizer = tokenizer, mlm = False)\n\ntrainer = Trainer(model = model,\n                 args = training_args,\n                 data_collator = data_collator,\n                 train_dataset = tokenized_train_dataset,\n                 eval_dataset = tokenized_test_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-01-25T12:24:27.049814Z","iopub.execute_input":"2023-01-25T12:24:27.050621Z","iopub.status.idle":"2023-01-25T12:24:32.444274Z","shell.execute_reply.started":"2023-01-25T12:24:27.050585Z","shell.execute_reply":"2023-01-25T12:24:32.443149Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-01-25T12:24:32.448094Z","iopub.execute_input":"2023-01-25T12:24:32.448386Z","iopub.status.idle":"2023-01-25T15:17:30.321837Z","shell.execute_reply.started":"2023-01-25T12:24:32.448360Z","shell.execute_reply":"2023-01-25T15:17:30.320925Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n***** Running training *****\n  Num examples = 25228\n  Num Epochs = 10\n  Instantaneous batch size per device = 16\n  Total train batch size (w. parallel, distributed & accumulation) = 32\n  Gradient Accumulation steps = 1\n  Total optimization steps = 7890\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='7890' max='7890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [7890/7890 2:52:51, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>8.586500</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>2.486800</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>2.390800</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>2.292000</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>2.254900</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>2.195700</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>2.146600</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>2.123700</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>2.070000</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>2.053800</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>2.031000</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>1.990800</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>1.982200</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>1.970400</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>1.946300</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=7890, training_loss=2.5375726465338837, metrics={'train_runtime': 10377.84, 'train_samples_per_second': 24.309, 'train_steps_per_second': 0.76, 'total_flos': 3.1874767981056e+16, 'train_loss': 2.5375726465338837, 'epoch': 10.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.save_model()\ntokenizer.save_pretrained(model_save_path)","metadata":{"execution":{"iopub.status.busy":"2023-01-25T15:17:30.323186Z","iopub.execute_input":"2023-01-25T15:17:30.324759Z","iopub.status.idle":"2023-01-25T15:17:31.401043Z","shell.execute_reply.started":"2023-01-25T15:17:30.324715Z","shell.execute_reply":"2023-01-25T15:17:31.400116Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"Saving model checkpoint to /kaggle/working/fine_tuned_model\nConfiguration saved in /kaggle/working/fine_tuned_model/config.json\nModel weights saved in /kaggle/working/fine_tuned_model/pytorch_model.bin\ntokenizer config file saved in /kaggle/working/fine_tuned_model/tokenizer_config.json\nSpecial tokens file saved in /kaggle/working/fine_tuned_model/special_tokens_map.json\nadded tokens file saved in /kaggle/working/fine_tuned_model/added_tokens.json\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/fine_tuned_model/tokenizer_config.json',\n '/kaggle/working/fine_tuned_model/special_tokens_map.json',\n '/kaggle/working/fine_tuned_model/vocab.json',\n '/kaggle/working/fine_tuned_model/merges.txt',\n '/kaggle/working/fine_tuned_model/added_tokens.json')"},"metadata":{}}]},{"cell_type":"code","source":"trainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2023-01-25T15:17:56.120950Z","iopub.execute_input":"2023-01-25T15:17:56.121348Z","iopub.status.idle":"2023-01-25T15:18:49.710292Z","shell.execute_reply.started":"2023-01-25T15:17:56.121317Z","shell.execute_reply":"2023-01-25T15:18:49.706691Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"***** Running Evaluation *****\n  Num examples = 6308\n  Batch size = 16\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='395' max='395' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [395/395 00:53]\n    </div>\n    "},"metadata":{}},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 2.634995460510254,\n 'eval_runtime': 53.5724,\n 'eval_samples_per_second': 117.747,\n 'eval_steps_per_second': 7.373,\n 'epoch': 10.0}"},"metadata":{}}]},{"cell_type":"code","source":"my_model = GPT2LMHeadModel.from_pretrained(model_save_path)\nmy_tokenizer = GPT2Tokenizer.from_pretrained(model_save_path)\n\ninput_text = my_tokenizer.bos_token\ninput_ids = my_tokenizer.encode(input_text, return_tensors = 'pt')\noutput = my_model.generate(input_ids, min_length = 20)\noutput = tokenizer.decode(output[0], skip_special_tokens = True)\nreal_output = str(output).split('.')\nprint(real_output[0] + '.')","metadata":{"execution":{"iopub.status.busy":"2023-01-25T16:14:08.268800Z","iopub.execute_input":"2023-01-25T16:14:08.269257Z","iopub.status.idle":"2023-01-25T16:14:11.289730Z","shell.execute_reply.started":"2023-01-25T16:14:08.269216Z","shell.execute_reply":"2023-01-25T16:14:11.288417Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"Error in callback <function _WandbInit._resume_backend at 0x7fc35daa3f80> (for pre_run_cell):\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/backcall/backcall.py\u001b[0m in \u001b[0;36madapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madapted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_resume_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resuming backend\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_jupyter_teardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_resume\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    615\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpublish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m         \u001b[0mresume\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 617\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py\u001b[0m in \u001b[0;36m_publish_resume\u001b[0;34m(self, resume)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRunRecord\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface_queue.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pb.Record\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_check\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The wandb backend process has shutdown\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mException\u001b[0m: The wandb backend process has shutdown"],"ename":"Exception","evalue":"The wandb backend process has shutdown","output_type":"error"},{"name":"stderr","text":"loading configuration file /kaggle/working/gpt2-business-ideas/config.json\nModel config GPT2Config {\n  \"_name_or_path\": \"gpt2\",\n  \"activation_function\": \"gelu_new\",\n  \"architectures\": [\n    \"GPT2LMHeadModel\"\n  ],\n  \"attn_pdrop\": 0.1,\n  \"bos_token_id\": 50256,\n  \"embd_pdrop\": 0.1,\n  \"eos_token_id\": 50257,\n  \"initializer_range\": 0.02,\n  \"layer_norm_epsilon\": 1e-05,\n  \"model_type\": \"gpt2\",\n  \"n_ctx\": 1024,\n  \"n_embd\": 768,\n  \"n_head\": 12,\n  \"n_inner\": null,\n  \"n_layer\": 12,\n  \"n_positions\": 1024,\n  \"pad_token_id\": 50258,\n  \"reorder_and_upcast_attn\": false,\n  \"resid_pdrop\": 0.1,\n  \"scale_attn_by_inverse_layer_idx\": false,\n  \"scale_attn_weights\": true,\n  \"summary_activation\": null,\n  \"summary_first_dropout\": 0.1,\n  \"summary_proj_to_labels\": true,\n  \"summary_type\": \"cls_index\",\n  \"summary_use_proj\": true,\n  \"task_specific_params\": {\n    \"text-generation\": {\n      \"do_sample\": true,\n      \"max_length\": 50\n    }\n  },\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.20.1\",\n  \"use_cache\": true,\n  \"vocab_size\": 50259\n}\n\nloading weights file /kaggle/working/gpt2-business-ideas/pytorch_model.bin\nAll model checkpoint weights were used when initializing GPT2LMHeadModel.\n\nAll the weights of GPT2LMHeadModel were initialized from the model checkpoint at /kaggle/working/gpt2-business-ideas.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\nloading file /kaggle/working/gpt2-business-ideas/vocab.json\nloading file /kaggle/working/gpt2-business-ideas/merges.txt\nloading file /kaggle/working/gpt2-business-ideas/added_tokens.json\nloading file /kaggle/working/gpt2-business-ideas/special_tokens_map.json\nloading file /kaggle/working/gpt2-business-ideas/tokenizer_config.json\nAdding <|EOS|> to the vocabulary\nAdding <|pad|> to the vocabulary\n","output_type":"stream"},{"name":"stdout","text":" A startup that helps people find the best deals on flights, hotels, and car rentals.\nError in callback <function _WandbInit._pause_backend at 0x7fc35daa3ef0> (for post_run_cell):\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/backcall/backcall.py\u001b[0m in \u001b[0;36madapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madapted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_pause_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    377\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"saved code: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resume_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         \u001b[0mpause\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface_shared.py\u001b[0m in \u001b[0;36m_publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpause\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresume\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/wandb/sdk/interface/interface_queue.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pb.Record\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_check\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The wandb backend process has shutdown\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mException\u001b[0m: The wandb backend process has shutdown"],"ename":"Exception","evalue":"The wandb backend process has shutdown","output_type":"error"}]}]}